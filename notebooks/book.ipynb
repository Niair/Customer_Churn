{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gUSv1YBAeOh"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "x31MKP9qGwOA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "oA5DCl6pHQcp"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "fAHU8XsrAjqw",
        "outputId": "2365bfcc-c210-455d-9eff-18c4f511965d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>married</th>\n",
              "      <th>number_of_dependents</th>\n",
              "      <th>city</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>number_of_referrals</th>\n",
              "      <th>tenure_in_months</th>\n",
              "      <th>offer</th>\n",
              "      <th>phone_service</th>\n",
              "      <th>avg_monthly_long_distance_charges</th>\n",
              "      <th>multiple_lines</th>\n",
              "      <th>internet_service</th>\n",
              "      <th>internet_type</th>\n",
              "      <th>avg_monthly_gb_download</th>\n",
              "      <th>online_security</th>\n",
              "      <th>online_backup</th>\n",
              "      <th>device_protection_plan</th>\n",
              "      <th>premium_tech_support</th>\n",
              "      <th>streaming_tv</th>\n",
              "      <th>streaming_movies</th>\n",
              "      <th>streaming_music</th>\n",
              "      <th>unlimited_data</th>\n",
              "      <th>contract</th>\n",
              "      <th>paperless_billing</th>\n",
              "      <th>payment_method</th>\n",
              "      <th>monthly_charge</th>\n",
              "      <th>total_charges</th>\n",
              "      <th>total_refunds</th>\n",
              "      <th>total_extra_data_charges</th>\n",
              "      <th>total_long_distance_charges</th>\n",
              "      <th>total_revenue</th>\n",
              "      <th>customer_status</th>\n",
              "      <th>has_offer</th>\n",
              "      <th>offer_popularity</th>\n",
              "      <th>has_extra_internet_charges</th>\n",
              "      <th>tenure_category</th>\n",
              "      <th>engagement_score</th>\n",
              "      <th>high_value</th>\n",
              "      <th>num_addon_services</th>\n",
              "      <th>churned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6878</th>\n",
              "      <td>9770-LXDBK</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>90006</td>\n",
              "      <td>34.048013</td>\n",
              "      <td>-118.293953</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Offer E</td>\n",
              "      <td>Yes</td>\n",
              "      <td>14</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No Internet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Month-to-Month</td>\n",
              "      <td>No</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>20.40</td>\n",
              "      <td>63.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>44.37</td>\n",
              "      <td>107.52</td>\n",
              "      <td>Joined</td>\n",
              "      <td>1</td>\n",
              "      <td>0.114298</td>\n",
              "      <td>0</td>\n",
              "      <td>0-1 Year</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6705</th>\n",
              "      <td>9522-ZSINC</td>\n",
              "      <td>Male</td>\n",
              "      <td>34</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>Santa Rosa</td>\n",
              "      <td>95409</td>\n",
              "      <td>38.468893</td>\n",
              "      <td>-122.580539</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>Offer D</td>\n",
              "      <td>Yes</td>\n",
              "      <td>7</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No Internet</td>\n",
              "      <td>0.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>One Year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bank Withdrawal</td>\n",
              "      <td>19.95</td>\n",
              "      <td>253.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>95.29</td>\n",
              "      <td>349.09</td>\n",
              "      <td>Stayed</td>\n",
              "      <td>1</td>\n",
              "      <td>0.085475</td>\n",
              "      <td>0</td>\n",
              "      <td>1-2 Years</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2941</th>\n",
              "      <td>4193-ORFCL</td>\n",
              "      <td>Female</td>\n",
              "      <td>80</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>North Hollywood</td>\n",
              "      <td>91606</td>\n",
              "      <td>34.187599</td>\n",
              "      <td>-118.387125</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Offer E</td>\n",
              "      <td>Yes</td>\n",
              "      <td>15</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>DSL</td>\n",
              "      <td>14.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Month-to-Month</td>\n",
              "      <td>No</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>45.10</td>\n",
              "      <td>45.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>15.24</td>\n",
              "      <td>60.34</td>\n",
              "      <td>Churned</td>\n",
              "      <td>1</td>\n",
              "      <td>0.114298</td>\n",
              "      <td>0</td>\n",
              "      <td>0-1 Year</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4297</th>\n",
              "      <td>6050-IJRHS</td>\n",
              "      <td>Female</td>\n",
              "      <td>47</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>Chino Hills</td>\n",
              "      <td>91709</td>\n",
              "      <td>33.942895</td>\n",
              "      <td>-117.725644</td>\n",
              "      <td>2</td>\n",
              "      <td>70</td>\n",
              "      <td>Offer A</td>\n",
              "      <td>Yes</td>\n",
              "      <td>5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fiber Optic</td>\n",
              "      <td>19.0</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>One Year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bank Withdrawal</td>\n",
              "      <td>106.50</td>\n",
              "      <td>7397.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>415.10</td>\n",
              "      <td>7812.10</td>\n",
              "      <td>Stayed</td>\n",
              "      <td>1</td>\n",
              "      <td>0.073832</td>\n",
              "      <td>0</td>\n",
              "      <td>4+ Years</td>\n",
              "      <td>7</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3508</th>\n",
              "      <td>4973-MGTON</td>\n",
              "      <td>Female</td>\n",
              "      <td>33</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>Topaz</td>\n",
              "      <td>96133</td>\n",
              "      <td>38.636052</td>\n",
              "      <td>-119.489162</td>\n",
              "      <td>0</td>\n",
              "      <td>71</td>\n",
              "      <td>No Offer</td>\n",
              "      <td>Yes</td>\n",
              "      <td>3</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>DSL</td>\n",
              "      <td>26.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Two Year</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Credit Card</td>\n",
              "      <td>84.40</td>\n",
              "      <td>5969.30</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>219.39</td>\n",
              "      <td>6188.69</td>\n",
              "      <td>Stayed</td>\n",
              "      <td>0</td>\n",
              "      <td>0.550476</td>\n",
              "      <td>0</td>\n",
              "      <td>4+ Years</td>\n",
              "      <td>8</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6652</th>\n",
              "      <td>9465-RWMXL</td>\n",
              "      <td>Male</td>\n",
              "      <td>62</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "      <td>San Diego</td>\n",
              "      <td>92126</td>\n",
              "      <td>32.886925</td>\n",
              "      <td>-117.152162</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>Offer C</td>\n",
              "      <td>Yes</td>\n",
              "      <td>22</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Fiber Optic</td>\n",
              "      <td>11.0</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Month-to-Month</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Bank Withdrawal</td>\n",
              "      <td>78.90</td>\n",
              "      <td>2447.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>722.24</td>\n",
              "      <td>3170.19</td>\n",
              "      <td>Churned</td>\n",
              "      <td>1</td>\n",
              "      <td>0.058924</td>\n",
              "      <td>0</td>\n",
              "      <td>2-4 Years</td>\n",
              "      <td>3</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     customer_id  gender  age married  number_of_dependents             city  \\\n",
              "6878  9770-LXDBK  Female   42      No                     0      Los Angeles   \n",
              "6705  9522-ZSINC    Male   34      No                     0       Santa Rosa   \n",
              "2941  4193-ORFCL  Female   80      No                     0  North Hollywood   \n",
              "4297  6050-IJRHS  Female   47     Yes                     1      Chino Hills   \n",
              "3508  4973-MGTON  Female   33     Yes                     0            Topaz   \n",
              "6652  9465-RWMXL    Male   62     Yes                     0        San Diego   \n",
              "\n",
              "      zip_code   latitude   longitude  number_of_referrals  tenure_in_months  \\\n",
              "6878     90006  34.048013 -118.293953                    0                 3   \n",
              "6705     95409  38.468893 -122.580539                    0                13   \n",
              "2941     91606  34.187599 -118.387125                    0                 1   \n",
              "4297     91709  33.942895 -117.725644                    2                70   \n",
              "3508     96133  38.636052 -119.489162                    0                71   \n",
              "6652     92126  32.886925 -117.152162                    1                32   \n",
              "\n",
              "         offer phone_service  avg_monthly_long_distance_charges  \\\n",
              "6878   Offer E           Yes                                 14   \n",
              "6705   Offer D           Yes                                  7   \n",
              "2941   Offer E           Yes                                 15   \n",
              "4297   Offer A           Yes                                  5   \n",
              "3508  No Offer           Yes                                  3   \n",
              "6652   Offer C           Yes                                 22   \n",
              "\n",
              "     multiple_lines internet_service internet_type  avg_monthly_gb_download  \\\n",
              "6878             No               No   No Internet                      0.0   \n",
              "6705             No               No   No Internet                      0.0   \n",
              "2941             No              Yes           DSL                     14.0   \n",
              "4297            Yes              Yes   Fiber Optic                     19.0   \n",
              "3508             No              Yes           DSL                     26.0   \n",
              "6652            Yes              Yes   Fiber Optic                     11.0   \n",
              "\n",
              "     online_security online_backup device_protection_plan  \\\n",
              "6878              No            No                     No   \n",
              "6705              No            No                     No   \n",
              "2941              No            No                     No   \n",
              "4297              No           Yes                    Yes   \n",
              "3508             Yes           Yes                    Yes   \n",
              "6652              No            No                    Yes   \n",
              "\n",
              "     premium_tech_support streaming_tv streaming_movies streaming_music  \\\n",
              "6878                   No           No               No              No   \n",
              "6705                   No           No               No              No   \n",
              "2941                   No           No               No              No   \n",
              "4297                   No          Yes              Yes             Yes   \n",
              "3508                  Yes          Yes              Yes             Yes   \n",
              "6652                   No           No               No              No   \n",
              "\n",
              "     unlimited_data        contract paperless_billing   payment_method  \\\n",
              "6878             No  Month-to-Month                No      Credit Card   \n",
              "6705             No        One Year               Yes  Bank Withdrawal   \n",
              "2941            Yes  Month-to-Month                No      Credit Card   \n",
              "4297            Yes        One Year               Yes  Bank Withdrawal   \n",
              "3508            Yes        Two Year               Yes      Credit Card   \n",
              "6652            Yes  Month-to-Month               Yes  Bank Withdrawal   \n",
              "\n",
              "      monthly_charge  total_charges  total_refunds  total_extra_data_charges  \\\n",
              "6878           20.40          63.15            0.0                         0   \n",
              "6705           19.95         253.80            0.0                         0   \n",
              "2941           45.10          45.10            0.0                         0   \n",
              "4297          106.50        7397.00            0.0                         0   \n",
              "3508           84.40        5969.30            0.0                         0   \n",
              "6652           78.90        2447.95            0.0                         0   \n",
              "\n",
              "      total_long_distance_charges  total_revenue customer_status  has_offer  \\\n",
              "6878                        44.37         107.52          Joined          1   \n",
              "6705                        95.29         349.09          Stayed          1   \n",
              "2941                        15.24          60.34         Churned          1   \n",
              "4297                       415.10        7812.10          Stayed          1   \n",
              "3508                       219.39        6188.69          Stayed          0   \n",
              "6652                       722.24        3170.19         Churned          1   \n",
              "\n",
              "      offer_popularity  has_extra_internet_charges tenure_category  \\\n",
              "6878          0.114298                           0        0-1 Year   \n",
              "6705          0.085475                           0       1-2 Years   \n",
              "2941          0.114298                           0        0-1 Year   \n",
              "4297          0.073832                           0        4+ Years   \n",
              "3508          0.550476                           0        4+ Years   \n",
              "6652          0.058924                           0       2-4 Years   \n",
              "\n",
              "      engagement_score  high_value  num_addon_services  churned  \n",
              "6878                 0       False                   0    False  \n",
              "6705                 0       False                   0    False  \n",
              "2941                 1       False                   0     True  \n",
              "4297                 7        True                   2    False  \n",
              "3508                 8        True                   4    False  \n",
              "6652                 3       False                   1     True  "
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"E:/VS_Code/Projects/Customer_Churn/notebooks/data/processed_customer_churn_data.csv\")\n",
        "\n",
        "df.sample(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7043, 44)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdIXTgnO6VxS"
      },
      "source": [
        "#### **MODEL with Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BnvkLcoczO5v",
        "outputId": "887a6a6b-46c0-484c-bb2f-0b85e5d0c46d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from category_encoders) (2.3.1)\n",
            "Requirement already satisfied: pandas>=1.0.5 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from category_encoders) (2.3.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from category_encoders) (1.7.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from category_encoders) (1.16.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from category_encoders) (0.14.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "nWsXp3gjzO3T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp313-cp313-win_amd64.whl.metadata (1.5 kB)\n",
            "Collecting graphviz (from catboost)\n",
            "  Using cached graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: matplotlib in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from catboost) (3.10.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from catboost) (2.3.1)\n",
            "Requirement already satisfied: pandas>=0.24 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from catboost) (2.3.1)\n",
            "Requirement already satisfied: scipy in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: plotly in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from catboost) (6.2.0)\n",
            "Requirement already satisfied: six in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from matplotlib->catboost) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from plotly->catboost) (1.46.0)\n",
            "Downloading catboost-1.2.8-cp313-cp313-win_amd64.whl (102.4 MB)\n",
            "   ---------------------------------------- 0.0/102.4 MB ? eta -:--:--\n",
            "   - -------------------------------------- 4.7/102.4 MB 22.4 MB/s eta 0:00:05\n",
            "   --- ------------------------------------ 9.7/102.4 MB 25.6 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 19.4/102.4 MB 31.0 MB/s eta 0:00:03\n",
            "   ------------- -------------------------- 35.7/102.4 MB 43.9 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 35.7/102.4 MB 43.9 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 35.7/102.4 MB 43.9 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 35.7/102.4 MB 43.9 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 35.9/102.4 MB 21.0 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 55.8/102.4 MB 29.0 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 73.1/102.4 MB 34.5 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 78.6/102.4 MB 33.8 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 83.6/102.4 MB 33.1 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 89.9/102.4 MB 32.8 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 94.6/102.4 MB 32.1 MB/s eta 0:00:01\n",
            "   --------------------------------------  100.1/102.4 MB 31.6 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------  102.2/102.4 MB 31.4 MB/s eta 0:00:01\n",
            "   --------------------------------------- 102.4/102.4 MB 11.0 MB/s eta 0:00:00\n",
            "Using cached graphviz-0.21-py3-none-any.whl (47 kB)\n",
            "Installing collected packages: graphviz, catboost\n",
            "\n",
            "   ---------------------------------------- 0/2 [graphviz]\n",
            "   ---------------------------------------- 0/2 [graphviz]\n",
            "   ---------------------------------------- 0/2 [graphviz]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   -------------------- ------------------- 1/2 [catboost]\n",
            "   ---------------------------------------- 2/2 [catboost]\n",
            "\n",
            "Successfully installed catboost-1.2.8 graphviz-0.21\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5bZkrkp-9QLu",
        "outputId": "db6df4cb-0870-4e17-873a-847491bdbac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from optuna) (2.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from optuna) (25.0)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
            "  Using cached sqlalchemy-2.0.41-cp313-cp313-win_amd64.whl.metadata (9.8 kB)\n",
            "Collecting tqdm (from optuna)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: PyYAML in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna)\n",
            "  Downloading greenlet-3.2.3-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: colorama in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in e:\\vs_code\\projects\\customer_churn\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "Downloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "Using cached sqlalchemy-2.0.41-cp313-cp313-win_amd64.whl (2.1 MB)\n",
            "Downloading greenlet-3.2.3-cp313-cp313-win_amd64.whl (297 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
            "\n",
            "   ---------------------------------------- 0/7 [tqdm]\n",
            "   ---------------------------------------- 0/7 [tqdm]\n",
            "   ---------------------------------------- 0/7 [tqdm]\n",
            "   ---------------------------------------- 0/7 [tqdm]\n",
            "   ---------------------------------------- 0/7 [tqdm]\n",
            "   ----- ---------------------------------- 1/7 [Mako]\n",
            "   ----- ---------------------------------- 1/7 [Mako]\n",
            "   ----- ---------------------------------- 1/7 [Mako]\n",
            "   ----- ---------------------------------- 1/7 [Mako]\n",
            "   ----------- ---------------------------- 2/7 [greenlet]\n",
            "   ----------- ---------------------------- 2/7 [greenlet]\n",
            "   ----------- ---------------------------- 2/7 [greenlet]\n",
            "   ----------------- ---------------------- 3/7 [colorlog]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------- ----------------- 4/7 [sqlalchemy]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------- ----------- 5/7 [alembic]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------- ----- 6/7 [optuna]\n",
            "   ---------------------------------------- 7/7 [optuna]\n",
            "\n",
            "Successfully installed Mako-1.3.10 alembic-1.16.4 colorlog-6.9.0 greenlet-3.2.3 optuna-4.4.0 sqlalchemy-2.0.41 tqdm-4.67.1\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "k_GMwfiNITtC",
        "outputId": "0f7b7e65-214d-48f0-8068-2a8983bf3174"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from category_encoders import CatBoostEncoder\n",
        "from category_encoders.target_encoder import TargetEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Cl5IDPzrIIbK"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, accuracy_score,\n",
        "    precision_score, recall_score, f1_score,\n",
        "    make_scorer, confusion_matrix, classification_report\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "try:\n",
        "    sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
        "    from logger import logging\n",
        "    \n",
        "except ImportError:\n",
        "    \n",
        "    import logging\n",
        "    logging.basicConfig(\n",
        "      format = \"[ %(asctime)s ] %(lineno)d %(name)s - %(levelname)s - %(message)s\",\n",
        "      level = logging.INFO,\n",
        "\n",
        "    )\n",
        "    logger = logging.getLogger(__name__)\n",
        "    logger.warning(\"Could not import 'logger' from 'logger.py'. Falling back to default logging configuration.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "import optuna\n",
        "import optuna.visualization as vis\n",
        "from optuna.exceptions import TrialPruned\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AutoMLTrainer:\n",
        "    def __init__(self, x_train, y_train, x_test, y_test, num_cols, cat_cols):\n",
        "        self.x_train = x_train\n",
        "        self.y_train = y_train\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "        self.numerical_cols = num_cols\n",
        "        self.categorical_cols = cat_cols\n",
        "        \n",
        "        # Validate and encode target\n",
        "        self._validate_and_encode_target()\n",
        "        \n",
        "        # Initialize results storage\n",
        "        self.results = []\n",
        "        self.best_models = {}\n",
        "        self.best_model = None\n",
        "        self.best_model_name = None\n",
        "        self.studies = {}\n",
        "        \n",
        "        # Configure encoders with robust settings\n",
        "        self.encoders = {\n",
        "            'onehot': OneHotEncoder(handle_unknown='ignore', sparse_output=False),\n",
        "            'target': TargetEncoder(),\n",
        "            'catboost_enc': CatBoostEncoder()\n",
        "        }\n",
        "        \n",
        "        # Optimized models with efficient hyperparameter spaces\n",
        "        self.models = {\n",
        "            'LogisticRegression': {\n",
        "                'model': LogisticRegression,\n",
        "                'params': lambda trial: {\n",
        "                    'classifier__C': trial.suggest_float('C', 1e-3, 100, log=True),\n",
        "                    'classifier__solver': trial.suggest_categorical('solver', ['lbfgs', 'saga']),\n",
        "                    'classifier__max_iter': 1000,\n",
        "                    'classifier__class_weight': 'balanced',\n",
        "                    'classifier__n_jobs': -1\n",
        "                }\n",
        "            },\n",
        "            'RandomForest': {\n",
        "                'model': RandomForestClassifier,\n",
        "                'params': lambda trial: {\n",
        "                    'classifier__n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "                    'classifier__max_depth': trial.suggest_int('max_depth', 5, 20),\n",
        "                    'classifier__min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
        "                    'classifier__class_weight': 'balanced',\n",
        "                    'classifier__n_jobs': -1\n",
        "                }\n",
        "            },\n",
        "            'XGBoost': {\n",
        "                'model': XGBClassifier,\n",
        "                'params': lambda trial: {\n",
        "                    'classifier__n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "                    'classifier__learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "                    'classifier__max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "                    'classifier__subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "                    'classifier__tree_method': 'hist'  # Faster training\n",
        "                }\n",
        "            },\n",
        "            'CatBoost': {\n",
        "                'model': CatBoostClassifier,\n",
        "                'params': lambda trial: {\n",
        "                    'classifier__iterations': trial.suggest_int('iterations', 500, 1000),\n",
        "                    'classifier__learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "                    'classifier__depth': trial.suggest_int('depth', 4, 8),\n",
        "                    'classifier__l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 5),\n",
        "                    'classifier__auto_class_weights': 'Balanced',\n",
        "                    'classifier__verbose': False,\n",
        "                    'classifier__task_type': 'CPU'  # Ensure CPU mode\n",
        "                }\n",
        "            },\n",
        "            'LightGBM': {\n",
        "                'model': LGBMClassifier,\n",
        "                'params': lambda trial: {\n",
        "                    'classifier__n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "                    'classifier__learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "                    'classifier__num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "                    'classifier__max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "                    'classifier__min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
        "                    'classifier__class_weight': 'balanced',\n",
        "                    'classifier__n_jobs': -1\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # Validate feature columns\n",
        "        self._validate_features()\n",
        "    \n",
        "    def _validate_and_encode_target(self):\n",
        "        \"\"\"Validate and encode target variable safely\"\"\"\n",
        "        # Check target dtype\n",
        "        if self.y_train.dtype == 'object' or self.y_train.dtype.name == 'category':\n",
        "            self.label_encoder = LabelEncoder()\n",
        "            self.y_train = self.label_encoder.fit_transform(self.y_train)\n",
        "            self.y_test = self.label_encoder.transform(self.y_test)\n",
        "            logger.info(\"Encoded categorical target variable\")\n",
        "        \n",
        "        # Check for binary classification\n",
        "        self.n_classes = len(np.unique(self.y_train))\n",
        "        logger.info(f\"Classification task with {self.n_classes} classes\")\n",
        "        \n",
        "        if self.n_classes > 2:\n",
        "            logger.warning(\"Multiclass classification detected. Some metrics may be affected.\")\n",
        "    \n",
        "    def _validate_features(self):\n",
        "        \"\"\"Validate features and remove problematic columns\"\"\"\n",
        "        # Remove constant numerical features\n",
        "        constant_cols = []\n",
        "        for col in self.numerical_cols:\n",
        "            if self.x_train[col].nunique() == 1:\n",
        "                constant_cols.append(col)\n",
        "        \n",
        "        if constant_cols:\n",
        "            logger.warning(f\"Removing constant features: {constant_cols}\")\n",
        "            self.numerical_cols = [col for col in self.numerical_cols if col not in constant_cols]\n",
        "        \n",
        "        # Check for missing values\n",
        "        missing_num = self.x_train[self.numerical_cols].isna().sum().sum()\n",
        "        missing_cat = self.x_train[self.categorical_cols].isna().sum().sum()\n",
        "        \n",
        "        if missing_num or missing_cat:\n",
        "            logger.warning(f\"Found {missing_num} missing numerical values and {missing_cat} missing categorical values\")\n",
        "    \n",
        "    def create_pipeline(self, encoder_name, model_name):\n",
        "        \"\"\"Create robust pipeline with imputation and preprocessing\"\"\"\n",
        "        # Numerical pipeline with imputation and scaling\n",
        "        num_pipeline = Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler())\n",
        "        ])\n",
        "        \n",
        "        # Categorical pipeline with imputation and encoding\n",
        "        cat_pipeline = Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "            ('encoder', self.encoders[encoder_name])\n",
        "        ])\n",
        "        \n",
        "        preprocessor = ColumnTransformer([\n",
        "            ('num', num_pipeline, self.numerical_cols),\n",
        "            ('cat', cat_pipeline, self.categorical_cols)\n",
        "        ])\n",
        "        \n",
        "        return Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', self.models[model_name]['model']())\n",
        "        ])\n",
        "    \n",
        "    def objective(self, trial, model_name, encoder_name):\n",
        "        \"\"\"Robust objective function with fold-level error handling\"\"\"\n",
        "        try:\n",
        "            pipeline = self.create_pipeline(encoder_name, model_name)\n",
        "            params = self.models[model_name]['params'](trial)\n",
        "            logger.debug(f\"Params suggested: {params}\")\n",
        "            pipeline.set_params(**params)\n",
        "\n",
        "            cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "            scores = []\n",
        "\n",
        "            for fold, (train_idx, val_idx) in enumerate(cv.split(self.x_train, self.y_train)):\n",
        "                try:\n",
        "                    X_fold_train = self.x_train.iloc[train_idx]\n",
        "                    y_fold_train = self.y_train.iloc[train_idx] if hasattr(self.y_train, 'iloc') else self.y_train[train_idx]\n",
        "                    pipeline.fit(X_fold_train, y_fold_train)\n",
        "\n",
        "                    X_val = self.x_train.iloc[val_idx]\n",
        "                    y_val = self.y_train.iloc[val_idx] if hasattr(self.y_train, 'iloc') else self.y_train[val_idx]\n",
        "\n",
        "                    if hasattr(pipeline.named_steps['classifier'], 'predict_proba'):\n",
        "                        y_proba = pipeline.predict_proba(X_val)\n",
        "\n",
        "                        score = roc_auc_score(\n",
        "                            y_val, \n",
        "                            y_proba[:, 1] if self.n_classes == 2 else y_proba, \n",
        "                            multi_class='ovr' if self.n_classes > 2 else 'raise'\n",
        "                        )\n",
        "                    else:\n",
        "                        logger.warning(f\"{model_name} does not support `predict_proba`. Using predictions for ROC AUC.\")\n",
        "                        y_pred = pipeline.predict(X_val)\n",
        "                        score = roc_auc_score(y_val, y_pred)\n",
        "\n",
        "                    scores.append(score)\n",
        "                    logger.debug(f\"{model_name}-{encoder_name} Fold {fold+1}: AUC = {score:.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.exception(f\"Objective failed during {model_name}-{encoder_name} with exception:\")\n",
        "                    return float('-inf')\n",
        "\n",
        "\n",
        "            mean_score = np.mean(scores)\n",
        "            logger.info(f\"{model_name}-{encoder_name} Mean AUC: {mean_score:.4f}\")\n",
        "            return mean_score\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Objective failed: {str(e)}\")\n",
        "            return float('-inf')\n",
        "\n",
        "    \n",
        "    def train_all(self, n_trials=20, timeout=1200):\n",
        "        \"\"\"Optimize all model-encoder combinations with enhanced stability\"\"\"\n",
        "        for model_name in self.models:\n",
        "            for encoder_name in self.encoders:\n",
        "                # Skip incompatible combinations\n",
        "                if model_name == 'CatBoost' and encoder_name != 'catboost_enc':\n",
        "                    continue\n",
        "                \n",
        "                combo_name = f\"{model_name}_{encoder_name}\"\n",
        "                logger.info(f\"\\n{'='*50}\")\n",
        "                logger.info(f\"Optimizing {combo_name}\")\n",
        "                logger.info(f\"{'='*50}\")\n",
        "                \n",
        "                try:\n",
        "                    # Create study with pruning\n",
        "                    study = optuna.create_study(\n",
        "                        direction='maximize',\n",
        "                        sampler=optuna.samplers.TPESampler(seed=42),\n",
        "                        pruner=optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
        "                    )\n",
        "                    \n",
        "                    # Optimize with timeout\n",
        "                    study.optimize(\n",
        "                        lambda trial: self.objective(trial, model_name, encoder_name),\n",
        "                        n_trials=n_trials,\n",
        "                        timeout=timeout,\n",
        "                        show_progress_bar=True\n",
        "                    )\n",
        "                    \n",
        "                    # Store study\n",
        "                    self.studies[combo_name] = study\n",
        "                    \n",
        "                    # Skip if no successful trials\n",
        "                    if not study.best_trial:\n",
        "                        logger.warning(f\"No successful trials for {combo_name}\")\n",
        "                        continue\n",
        "                    \n",
        "                    # Train best pipeline\n",
        "                    best_pipeline = self.create_pipeline(encoder_name, model_name)\n",
        "                    best_params = self.models[model_name]['params'](study.best_trial)\n",
        "                    best_pipeline.set_params(**best_params)\n",
        "                    best_pipeline.fit(self.x_train, self.y_train)\n",
        "                    \n",
        "                    # Evaluate\n",
        "                    y_pred = best_pipeline.predict(self.x_test)\n",
        "                    y_proba = best_pipeline.predict_proba(self.x_test)[:, 1] if self.n_classes == 2 else None\n",
        "                    \n",
        "                    # Calculate metrics\n",
        "                    metrics = {\n",
        "                        'model': model_name,\n",
        "                        'encoder': encoder_name,\n",
        "                        'accuracy': accuracy_score(self.y_test, y_pred),\n",
        "                        'precision': precision_score(self.y_test, y_pred, average='weighted'),\n",
        "                        'recall': recall_score(self.y_test, y_pred, average='weighted'),\n",
        "                        'f1': f1_score(self.y_test, y_pred, average='weighted'),\n",
        "                        'best_params': best_params\n",
        "                    }\n",
        "                    \n",
        "                    # Add AUC if available\n",
        "                    if y_proba is not None:\n",
        "                        metrics['auc_roc'] = roc_auc_score(self.y_test, y_proba)\n",
        "                    elif self.n_classes == 2:\n",
        "                        metrics['auc_roc'] = roc_auc_score(self.y_test, y_pred)\n",
        "                    else:\n",
        "                        metrics['auc_roc'] = np.nan\n",
        "                    \n",
        "                    self.results.append(metrics)\n",
        "                    self.best_models[combo_name] = best_pipeline\n",
        "                    logger.info(f\"{combo_name} | Test AUC: {metrics.get('auc_roc', np.nan):.4f}\")\n",
        "                    \n",
        "                    # Visualize optimization\n",
        "                    self._plot_optimization_results(study, model_name, encoder_name)\n",
        "                \n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Optimization failed for {combo_name}: {str(e)}\")\n",
        "        \n",
        "        # Finalize results\n",
        "        if self.results:\n",
        "            self._finalize_results()\n",
        "            return True\n",
        "        else:\n",
        "            logger.error(\"No models successfully completed optimization\")\n",
        "            return False\n",
        "    \n",
        "    def _plot_optimization_results(self, study, model_name, encoder_name):\n",
        "        \"\"\"Visualize optimization results\"\"\"\n",
        "        try:\n",
        "            # Optimization history\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plot_optimization_history(study)\n",
        "            plt.title(f\"{model_name}-{encoder_name} Optimization History\", fontsize=14)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"opt_history_{model_name}_{encoder_name}.png\", dpi=150)\n",
        "            plt.close()\n",
        "            \n",
        "            # Parameter importance\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            plot_param_importances(study)\n",
        "            plt.title(f\"{model_name}-{encoder_name} Parameter Importance\", fontsize=14)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f\"param_importance_{model_name}_{encoder_name}.png\", dpi=150)\n",
        "            plt.close()\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Visualization failed: {str(e)}\")\n",
        "    \n",
        "    def _finalize_results(self):\n",
        "        \"\"\"Process and store final results\"\"\"\n",
        "        self.results_df = pd.DataFrame(self.results)\n",
        "        \n",
        "        # Calculate mean score for sorting\n",
        "        if 'auc_roc' in self.results_df:\n",
        "            self.results_df['mean_score'] = self.results_df['auc_roc']\n",
        "        else:\n",
        "            self.results_df['mean_score'] = self.results_df['accuracy']\n",
        "        \n",
        "        # Sort and select best model\n",
        "        self.results_df = self.results_df.sort_values('mean_score', ascending=False)\n",
        "        best_combo = self.results_df.iloc[0]['model'] + '_' + self.results_df.iloc[0]['encoder']\n",
        "        self.best_model = self.best_models[best_combo]\n",
        "        self.best_model_name = best_combo\n",
        "        \n",
        "        logger.info(f\"\\n{'='*50}\")\n",
        "        logger.info(f\"BEST MODEL: {best_combo}\")\n",
        "        logger.info(f\"SCORE: {self.results_df.iloc[0]['mean_score']:.4f}\")\n",
        "        logger.info(f\"{'='*50}\")\n",
        "        \n",
        "        # Save results\n",
        "        self.results_df.to_csv('automl_results.csv', index=False)\n",
        "        joblib.dump(self.best_model, 'best_model.pkl')\n",
        "    \n",
        "    def evaluate_best_model(self):\n",
        "        \"\"\"Comprehensive evaluation of best model\"\"\"\n",
        "        if not self.best_model:\n",
        "            logger.error(\"No best model available for evaluation\")\n",
        "            return None\n",
        "\n",
        "        y_pred = self.best_model.predict(self.x_test)\n",
        "\n",
        "        try:\n",
        "            if hasattr(self.best_model.named_steps['classifier'], 'predict_proba'):\n",
        "                y_proba = self.best_model.predict_proba(self.x_test)[:, 1] if self.n_classes == 2 else self.best_model.predict_proba(self.x_test)\n",
        "            else:\n",
        "                y_proba = None\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"predict_proba failed: {e}\")\n",
        "            y_proba = None\n",
        "\n",
        "        metrics = {\n",
        "            \"accuracy\": accuracy_score(self.y_test, y_pred),\n",
        "            \"precision\": precision_score(self.y_test, y_pred, average='weighted'),\n",
        "            \"recall\": recall_score(self.y_test, y_pred, average='weighted'),\n",
        "            \"f1\": f1_score(self.y_test, y_pred, average='weighted'),\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            if y_proba is not None:\n",
        "                metrics[\"auc_roc\"] = roc_auc_score(self.y_test, y_proba if self.n_classes > 2 else y_proba)\n",
        "            else:\n",
        "                metrics[\"auc_roc\"] = roc_auc_score(self.y_test, y_pred)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"ROC AUC calculation failed: {e}\")\n",
        "            metrics[\"auc_roc\"] = np.nan\n",
        "\n",
        "        metrics[\"classification_report\"] = classification_report(self.y_test, y_pred)\n",
        "\n",
        "        self._plot_confusion_matrix(y_pred, self.best_model_name)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    \n",
        "    def _plot_confusion_matrix(self, y_pred, model_name):\n",
        "        \"\"\"Plot confusion matrix with annotations\"\"\"\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
        "                    yticklabels=['Actual 0', 'Actual 1'])\n",
        "        plt.title(f'Confusion Matrix: {model_name}', fontsize=14)\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'confusion_matrix_{model_name}.png', dpi=300)\n",
        "        plt.close()\n",
        "    \n",
        "    def plot_model_comparison(self):\n",
        "        \"\"\"Visualize model comparison with enhanced aesthetics\"\"\"\n",
        "        if not hasattr(self, 'results_df') or self.results_df.empty:\n",
        "            logger.error(\"No results available for comparison\")\n",
        "            return\n",
        "        \n",
        "        # Create comparison data\n",
        "        plot_df = self.results_df.copy()\n",
        "        plot_df['model_encoder'] = plot_df['model'] + '_' + plot_df['encoder']\n",
        "        \n",
        "        plt.figure(figsize=(14, 8))\n",
        "        ax = sns.barplot(\n",
        "            x='auc_roc' if 'auc_roc' in plot_df else 'accuracy',\n",
        "            y='model_encoder',\n",
        "            data=plot_df.sort_values('auc_roc' if 'auc_roc' in plot_df else 'accuracy', ascending=False),\n",
        "            palette='viridis'\n",
        "        )\n",
        "        \n",
        "        # Add annotations\n",
        "        for p in ax.patches:\n",
        "            width = p.get_width()\n",
        "            ax.text(width + 0.01, p.get_y() + p.get_height()/2, \n",
        "                    f'{width:.3f}', \n",
        "                    ha='left', va='center')\n",
        "        \n",
        "        # Formatting\n",
        "        metric_name = 'AUC-ROC' if 'auc_roc' in plot_df else 'Accuracy'\n",
        "        plt.title(f'Model Performance Comparison ({metric_name})', fontsize=16)\n",
        "        plt.xlabel(metric_name, fontsize=14)\n",
        "        plt.ylabel('Model + Encoder', fontsize=14)\n",
        "        plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('model_performance_comparison.png', dpi=300)\n",
        "        plt.close()\n",
        "    \n",
        "    def cross_validate_best_model(self):\n",
        "        \"\"\"Cross-validate best model for stability assessment\"\"\"\n",
        "        if not self.best_model:\n",
        "            logger.error(\"No best model available for cross-validation\")\n",
        "            return None\n",
        "        \n",
        "        scoring = {\n",
        "            'accuracy': 'accuracy',\n",
        "            'precision': 'precision_weighted',\n",
        "            'recall': 'recall_weighted',\n",
        "            'f1': 'f1_weighted',\n",
        "            'roc_auc': 'roc_auc_ovr' if self.n_classes > 2 else 'roc_auc'\n",
        "        }\n",
        "        \n",
        "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        cv_results = cross_validate(\n",
        "            self.best_model, \n",
        "            self.x_train, \n",
        "            self.y_train,\n",
        "            cv=cv,\n",
        "            scoring=scoring,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "        \n",
        "        # Process results\n",
        "        cv_metrics = {}\n",
        "        for metric in scoring:\n",
        "            key = f\"mean_{metric}\"\n",
        "            cv_metrics[key] = np.mean(cv_results[f'test_{metric}'])\n",
        "            cv_metrics[f\"std_{metric}\"] = np.std(cv_results[f'test_{metric}'])\n",
        "        \n",
        "        return cv_metrics\n",
        "    \n",
        "    def get_best_hyperparameters(self):\n",
        "        \"\"\"Retrieve best hyperparameters in readable format\"\"\"\n",
        "        if not hasattr(self, 'results_df') or self.results_df.empty:\n",
        "            return None\n",
        "        \n",
        "        best_row = self.results_df.iloc[0]\n",
        "        return {\n",
        "            'model': best_row['model'],\n",
        "            'encoder': best_row['encoder'],\n",
        "            'hyperparameters': best_row['best_params']\n",
        "        }\n",
        "    \n",
        "    def __str__(self):\n",
        "        status = f\"Best Model: {self.best_model_name}\" if self.best_model_name else \"Not trained\"\n",
        "        return f\"<AutoMLTrainer | {status}>\"\n",
        "\n",
        "# Sample usage (assuming df is loaded)\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    # df.drop(columns=['customer_id'], inplace=True)\n",
        "\n",
        "    # Prepare data\n",
        "    X = df.drop(columns=['customer_status'])\n",
        "    y = df['customer_status']\n",
        "    \n",
        "    # Split data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "    \n",
        "    # Identify feature types\n",
        "    numerical_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "    categorical_cols = X.select_dtypes(exclude=np.number).columns.tolist()\n",
        "    \n",
        "    # Initialize and run trainer\n",
        "    trainer = AutoMLTrainer(x_train, y_train, x_test, y_test, numerical_cols, categorical_cols)\n",
        "    success = trainer.train_all(n_trials=20, timeout=1200)\n",
        "    \n",
        "    if success:\n",
        "        # Evaluate best model\n",
        "        metrics = trainer.evaluate_best_model()\n",
        "        logger.info(\"\\nBest Model Metrics:\")\n",
        "        for k, v in metrics.items():\n",
        "            if k != \"classification_report\":\n",
        "                logger.info(f\"{k}: {v:.4f}\")\n",
        "        \n",
        "        logger.info(\"\\nClassification Report:\")\n",
        "        logger.info(metrics[\"classification_report\"])\n",
        "        \n",
        "        # Visualize comparison\n",
        "        trainer.plot_model_comparison()\n",
        "        \n",
        "        # Show best hyperparameters\n",
        "        best_params = trainer.get_best_hyperparameters()\n",
        "        logger.info(\"\\nBest Hyperparameters:\")\n",
        "        logger.info(best_params)\n",
        "        \n",
        "        # Cross-validate best model\n",
        "        cv_metrics = trainer.cross_validate_best_model()\n",
        "        logger.info(\"\\nCross-Validation Metrics:\")\n",
        "        for k, v in cv_metrics.items():\n",
        "            logger.info(f\"{k}: {v:.4f}\")\n",
        "\n",
        "    # Save final report\n",
        "    logger.info(\"AutoML training completed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9907735982966643\n"
          ]
        }
      ],
      "source": [
        "pipe = trainer.create_pipeline('onehot', 'LogisticRegression')\n",
        "pipe.set_params(**{\n",
        "    'classifier__C': 1.0,\n",
        "    'classifier__solver': 'lbfgs'\n",
        "})\n",
        "pipe.fit(trainer.x_train, trainer.y_train)\n",
        "print(pipe.score(trainer.x_test, trainer.y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7V5lAKNRr7xG",
        "w9XR_PT8jpa5",
        "zmP91_c2od3X"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
